{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Connect to Elasticsearch\n",
    "# ----------------------------\n",
    "es = Elasticsearch(\n",
    "    \"https://3322940df94141d98ca5135e9d80ba54.us-central1.gcp.cloud.es.io:443\",\n",
    "    basic_auth=(\"test\", \"test123456\")\n",
    ")\n",
    "index_name = \"test-reviews\"\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Load CSV\n",
    "# ----------------------------\n",
    "csv_file = \"/Users/aasawarisahasrabuddhe/PyCharmMiscProject/pubmedqa_downloads/Reviews_10k.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "print(f\"✅ Loaded CSV with {len(df)} rows\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Create index with mapping (Text + embedding_vector)\n",
    "# ----------------------------\n",
    "if not es.indices.exists(index=index_name):\n",
    "    mapping = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"Text\": {\"type\": \"text\"},\n",
    "                \"embedding_vector\": {\"type\": \"dense_vector\", \"dims\": 384, \"index\": True, \"similarity\": \"cosine\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index=index_name, body=mapping)\n",
    "    print(f\"✅ Created index '{index_name}' with mapping\")\n",
    "else:\n",
    "    print(f\"✅ Index '{index_name}' already exists\")\n",
    "\n",
    "from elasticsearch import helpers\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Prepare documents for bulk\n",
    "# ----------------------------\n",
    "actions = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = str(row['Text']).strip()\n",
    "    if not text:\n",
    "        continue\n",
    "    action = {\n",
    "        \"_index\": index_name,\n",
    "        \"_id\": idx,\n",
    "        \"_source\": {\n",
    "            \"Text\": text\n",
    "        }\n",
    "    }\n",
    "    actions.append(action)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Bulk index documents\n",
    "# ----------------------------\n",
    "success, failed = helpers.bulk(es, actions)\n",
    "print(f\"\\n✅ Indexed {success} documents, failed: {len(failed)}\")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load embedding model\n",
    "# ----------------------------\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"✅ Model loaded\")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Fetch all documents (corrected)\n",
    "# ----------------------------\n",
    "docs = es.search(\n",
    "    index=index_name,\n",
    "    body={\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"size\": 100  # move size inside the body\n",
    "    }\n",
    ")\n",
    "print(f\"ℹ Found {len(docs['hits']['hits'])} documents to process\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Generate embeddings and update documents\n",
    "# ----------------------------\n",
    "updated_count = 0\n",
    "\n",
    "for hit in tqdm(docs['hits']['hits'], desc=\"Updating embeddings\"):\n",
    "    doc_id = hit['_id']\n",
    "    text = hit['_source'].get('Text', '').strip()\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    # Generate embedding\n",
    "    embedding = model.encode(text).tolist()\n",
    "\n",
    "    # Update document in ES\n",
    "    es.update(\n",
    "        index=index_name,\n",
    "        id=doc_id,\n",
    "        body={\"doc\": {\"embedding_vector\": embedding}},\n",
    "        refresh=True  # ensure embedding is visible immediately\n",
    "    )\n",
    "    updated_count += 1\n",
    "\n",
    "print(f\"\\n✅ Updated embeddings for {updated_count} documents\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Helper: pretty print results\n",
    "# ----------------------------\n",
    "def pretty_print(results):\n",
    "    for i, hit in enumerate(results[\"hits\"][\"hits\"], 1):\n",
    "        score = hit.get('_score', 0)\n",
    "        text = hit['_source'].get('Text', '')[:150]\n",
    "        print(f\"{i}. Score: {score:.4f} | Text: {text}...\\n\")\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Full-text search\n",
    "# ----------------------------\n",
    "def full_text_search(query, size=5):\n",
    "    body = {\"size\": size, \"query\": {\"match\": {\"Text\": query}}, \"_source\": [\"Text\"]}\n",
    "    start = time.time()\n",
    "    results = es.search(index=index_name, body=body)\n",
    "    duration = time.time() - start\n",
    "    print(f\"\\n--- Full-Text Search ({results['hits']['total']['value']} matches) ---\")\n",
    "    pretty_print(results)\n",
    "    print(f\"Execution time: {duration:.4f} sec\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Vector search\n",
    "# ----------------------------\n",
    "def vector_search(query, size=5):\n",
    "    query_vector = model.encode(query).tolist()\n",
    "    body = {\n",
    "        \"size\": size,\n",
    "        \"knn\": {\n",
    "            \"field\": \"embedding_vector\",\n",
    "            \"query_vector\": query_vector,\n",
    "            \"k\": size,\n",
    "            \"num_candidates\": 100\n",
    "        },\n",
    "        \"_source\": [\"Text\"]\n",
    "    }\n",
    "    start = time.time()\n",
    "    results = es.search(index=index_name, body=body)\n",
    "    duration = time.time() - start\n",
    "    print(f\"\\n--- Vector Search ---\")\n",
    "    pretty_print(results)\n",
    "    print(f\"Execution time: {duration:.4f} sec\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Hybrid search\n",
    "# ----------------------------\n",
    "def hybrid_search(query, size=5, text_weight=0.5, vector_weight=0.5):\n",
    "    query_vector = model.encode(query).tolist()\n",
    "    body = {\n",
    "        \"size\": size,\n",
    "        \"query\": {\n",
    "            \"function_score\": {\n",
    "                \"query\": {\"match\": {\"Text\": query}},\n",
    "                \"functions\": [\n",
    "                    {\n",
    "                        \"script_score\": {\n",
    "                            \"script\": {\n",
    "                                \"source\": \"cosineSimilarity(params.query_vector, 'embedding_vector') + 1.0\",\n",
    "                                \"params\": {\"query_vector\": query_vector}\n",
    "                            }\n",
    "                        },\n",
    "                        \"weight\": vector_weight\n",
    "                    }\n",
    "                ],\n",
    "                \"score_mode\": \"sum\",\n",
    "                \"boost_mode\": \"sum\"\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"Text\"]\n",
    "    }\n",
    "    start = time.time()\n",
    "    results = es.search(index=index_name, body=body)\n",
    "    duration = time.time() - start\n",
    "    print(f\"\\n--- Hybrid Search ---\")\n",
    "    pretty_print(results)\n",
    "    print(f\"Execution time: {duration:.4f} sec\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Run all searches\n",
    "# ----------------------------\n",
    "query_text = \"good for puppies\"\n",
    "\n",
    "full_text_search(query_text)\n",
    "vector_search(query_text)\n",
    "hybrid_search(query_text)"
   ],
   "id": "f49eecc7cfce3fc1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
